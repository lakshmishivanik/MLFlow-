{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshmishivanik/MLFlow-/blob/main/MLflow_LLM_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoPlrDtLuJdI"
      },
      "source": [
        "#MLflow LLM Evaluation\n",
        "With the emerging of ChatGPT, LLMs have shown its power of text generation in various fields, such as question answering, translating and text summarization. Evaluating LLMs’ performance is slightly different from traditional ML models, as very often there is no single ground truth to compare against. MLflow provides an API mlflow.evaluate() to help evaluate your LLMs.\n",
        "\n",
        "MLflow’s LLM evaluation functionality consists of 3 main components:\n",
        "\n",
        "A model to evaluate: it can be an MLflow pyfunc model, a URI pointing to one registered MLflow model, or any python callable that represents your model, e.g, a HuggingFace text summarization pipeline.\n",
        "\n",
        "Metrics: the metrics to compute, LLM evaluate will use LLM metrics.\n",
        "\n",
        "Evaluation data: the data your model is evaluated at, it can be a pandas Dataframe, a python list, a numpy array or an mlflow.data.dataset.Dataset() instance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG4vcMsYuXIC"
      },
      "source": [
        "##Quickstart\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BV6CslQ35EC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"  # Replace with your actual key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXR4euJpAZVd",
        "outputId": "ee6a4564-9d80-4fb8-a958-19769dcaebae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.20.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting mlflow-skinny==2.20.3 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.20.3-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.20.3->mlflow)\n",
            "  Downloading databricks_sdk-0.44.1-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.4.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (2.38.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.3->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (0.37b0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.20.3-py3-none-any.whl (28.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.20.3-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.44.1-py3-none-any.whl (648 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.7/648.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyngrok, Mako, gunicorn, graphql-core, dill, multiprocess, graphql-relay, docker, alembic, graphene, databricks-sdk, anthropic, mlflow-skinny, datasets, mlflow\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 anthropic-0.49.0 databricks-sdk-0.44.1 datasets-3.3.2 dill-0.3.8 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.20.3 mlflow-skinny-2.20.3 multiprocess-0.70.16 pyngrok-7.2.3 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow pandas datasets transformers anthropic pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE_cAF-4OedR",
        "outputId": "242783c9-67f2-4567-8a42-45f1e069c5cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (2.20.3)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.49.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: mlflow-skinny==2.20.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.20.3)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (0.44.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (2.38.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.3->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (0.37b0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.4.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow anthropic pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHnb0moYEmTC",
        "outputId": "0d0119ae-a43c-4c71-aa2d-42565f328ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-VcESMCvyc0"
      },
      "source": [
        "Below is a simple example that gives a quick overview of how to evaluate LLMs with MLflow. The example builds a simple question-answering evaluation pipeline using Anthropic's Claude API. It interacts with the Claude API to get responses and then evaluates the responses based on a custom metric. The results, including the average matching accuracy, are logged to MLflow. You can paste it to your IPython or local editor and execute it, and install missing dependencies as prompted. Running the code requires an Anthropic API key, if you don’t have one, you can set it up by following the Anthropic guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJPGSoEJsqX1",
        "outputId": "492c0113-2ac0-4ed1-8ada-b142f5ff4f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Claude Response: MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It provides a set of tools and APIs for tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\n",
            "Claude Response: Apache Spark is an open-source distributed computing system used for big data processing and analytics. It provides an interface for programming entire clusters with implicit data parallelism and fault tolerance, making it an efficient tool for handling large-scale data processing tasks.\n",
            "Simple Matching Accuracy: 1.0\n",
            "            inputs                                       ground_truth  \\\n",
            "0  What is MLflow?  MLflow is an open-source platform for managing...   \n",
            "1   What is Spark?  Apache Spark is an open-source, distributed co...   \n",
            "\n",
            "                                     Claude_response  metric  \n",
            "0  MLflow is an open-source platform for managing...     1.0  \n",
            "1  Apache Spark is an open-source distributed com...     1.0  \n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import string  # Import string module for punctuation removal\n",
        "\n",
        "# 1. Set your Anthropic API key\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"  # Replace!\n",
        "\n",
        "# 2. Define your evaluation data\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "        \"ground_truth\": [\n",
        "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
        "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
        "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
        "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
        "            \"machine learning models.\",\n",
        "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
        "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
        "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
        "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
        "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
        "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define a function to interact with the Claude API\n",
        "def anthropic_model(prompt, system_prompt):\n",
        "    client = anthropic.Anthropic()\n",
        "    try:\n",
        "        message = client.messages.create(\n",
        "            model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "            max_tokens=1024,\n",
        "            system=system_prompt,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        return message.content[0].text\n",
        "    except anthropic.APIStatusError as e:\n",
        "        print(f\"Anthropic API Error: {e}\")\n",
        "        return None\n",
        "    except anthropic.RateLimitError as e:\n",
        "        print(f\"Rate limit exceeded. Waiting and retrying...\")\n",
        "        time.sleep(60)\n",
        "        return anthropic_model(prompt, system_prompt)  # Retry\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# 4. Modify the evaluation loop to use the Claude API\n",
        "with mlflow.start_run() as run:\n",
        "    system_prompt = \"Answer the following question in two sentences\"\n",
        "\n",
        "    # Create a new column with the Claude responses\n",
        "    responses = []\n",
        "    for i in range(len(eval_data)):\n",
        "        response = anthropic_model(eval_data[\"inputs\"][i], system_prompt)\n",
        "        responses.append(response)\n",
        "        print(f\"Claude Response: {response}\") # Print for debugging\n",
        "\n",
        "    eval_data[\"Claude_response\"] = responses\n",
        "\n",
        "    # 5. Evaluate the model (using custom evaluation logic if needed)\n",
        "    def simple_metric(row):\n",
        "        claude_response = row[\"Claude_response\"]\n",
        "        if claude_response is None:  # Handle None values gracefully\n",
        "            return 0.0\n",
        "\n",
        "        ground_truth = row[\"ground_truth\"].lower()\n",
        "        claude_response = claude_response.lower()\n",
        "\n",
        "        # Remove punctuation from both strings\n",
        "        ground_truth = ground_truth.translate(str.maketrans('', '', string.punctuation))\n",
        "        claude_response = claude_response.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "        ground_truth_words = ground_truth.split()\n",
        "        claude_words = claude_response.split()\n",
        "\n",
        "        # Check if *any* of the ground truth words are in the Claude response\n",
        "        if any(word in claude_words for word in ground_truth_words):\n",
        "            return 1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    eval_data[\"metric\"] = eval_data.apply(simple_metric, axis=1)  # Apply the metric to each row\n",
        "    average_metric = eval_data[\"metric\"].mean()\n",
        "\n",
        "    # Log the metric to MLflow\n",
        "    mlflow.log_metric(\"simple_matching_accuracy\", average_metric)\n",
        "\n",
        "    print(f\"Simple Matching Accuracy: {average_metric}\")\n",
        "    print(eval_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkkRow0zv8cW"
      },
      "source": [
        "##LLM Evaluation Metrics\n",
        "There are two types of LLM evaluation metrics in MLflow:\n",
        "\n",
        "Heuristic-based metrics: These metrics calculate a score for each data record (row in terms of Pandas/Spark dataframe), based on certain functions, such as: Rouge (rougeL()), Flesch Kincaid (flesch_kincaid_grade_level()) or Bilingual Evaluation Understudy (BLEU) (bleu()). These metrics are similar to traditional continuous value metrics. For the list of built-in heuristic metrics and how to define a custom metric with your own function definition, see the Heuristic-based Metrics section.\n",
        "\n",
        "LLM-as-a-Judge metrics: LLM-as-a-Judge is a new type of metric that uses LLMs to score the quality of model outputs. It overcomes the limitations of heuristic-based metrics, which often miss nuances like context and semantic accuracy. LLM-as-a-Judge metrics provides a more human-like evaluation for complex language tasks while being more scalable and cost-effective than human evaluation. MLflow provides various built-in LLM-as-a-Judge metrics and supports creating custom metrics with your own prompt, grading criteria, and reference examples. See the LLM-as-a-Judge Metrics section for more details.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6SvpyvFweBx"
      },
      "source": [
        "###Heuristic-based Metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmrYoIIOtsXz",
        "outputId": "dc78656c-8a18-4e81-e15d-50c4b92baceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cmudict (from textstat)\n",
            "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat, evaluate\n",
            "Successfully installed cmudict-1.0.32 evaluate-0.4.3 pyphen-0.17.2 textstat-0.7.5\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate textstat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iLYjS6Mw5PC"
      },
      "source": [
        "MLflow LLM evaluation includes default collections of metrics for pre-selected tasks, e.g, “question-answering”. Depending on the LLM use case that you are evaluating, these pre-defined collections can greatly simplify the process of running evaluations. To use defaults metrics for pre-selected tasks, specify the model_type argument in mlflow.evaluate(), as shown by the example below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677,
          "referenced_widgets": [
            "6f40ceb9706b48c2945386766f72050b",
            "d29e33fde11941f4ade74102a50b458e",
            "6fbcac8ffcb748dab17750d69e1130b4",
            "1708b949bc8244bdb1fc0708985f9b68",
            "627706204c714b0f9adb90e4863a675a",
            "09bf686009ce464091955d269b42eec2",
            "b8a561e28ff04779a77e890b08d82b4e",
            "d5b39e8422e141f58c0e6e6a3cd5c78f",
            "c9fc1c26ec0440ebb735de71d674e282",
            "1ed8ae9bb2fc4b06ae7051b584cb1fa5",
            "340980ff0da24d3aacde51ea337a6327",
            "12061ca69e724bccad2f896b27817458",
            "2338698c053d4a8ba97966dff3ff7ce4",
            "b2a5991393fe4e5ea3ac4419250b7d10",
            "4ca3c4d534e846c5b6e07773f55bd780",
            "9380fd47c089424484129b412b6f8aaa",
            "255d966a606e4acf96b6bc3b3dfc4a20",
            "afaabd1885c6416f95dbba4ec96540bb",
            "e6b088f268c84f6f9625698d5bf87878",
            "daf3a0400bad4f4689ff56055ac7dfbb",
            "e3617d3da5f3429c86ce71dba891a651",
            "b6d7f07d062646cca3ca3da576de50da",
            "84b70dbbc3544a3a96805073aee3b4a5",
            "33d7611f6d42497a8b3d693f725c7630",
            "72a0b15624784ae1a4dc508c26be6335",
            "53586e54851f4464a5daef12409605aa",
            "3b8f2da6455641b3bffb2a1a2eb7993a",
            "82e651bc7d814967b1db88ec26b2493d",
            "3bb59c69a0d346b49b1f66df9dca83e5",
            "0eee4cbb64594125ba097ef895149332",
            "997b7f58dd54471986b2bef7a5c29e08",
            "ad114a55cdae4d9b837f5b0f65a7939b",
            "5defa7fea1f74fa48e3c11973593593a",
            "25d124021a544862b00d969180406d8b",
            "a8725c3887d34a9586dbff91898fcb4e",
            "213a3e1df2a2458b8555fbb2f80764ac",
            "148b35bf7abb45bfab48e616cd7fddc0",
            "25c532defe1647d892e1020963d01324",
            "f77597522a7e4a1288874c0018cd6c9a",
            "bc1be7dbf47c477f9efe8b9c03158b21",
            "f184c39eae274e44a230a53916cabdce",
            "e9e4c250030b4c93b53594244723d7de",
            "287d8901f1e14572b140825c55450a56",
            "f7d972513c3e4d719632d13b8c8feeed",
            "638ec5ff2a6b43d78a0bcbaaa0a112fe",
            "91ae8a790b014246b39d7038c731ecb7",
            "6439d2cfa7da4ab79249d052b9ac4b88",
            "4b93ab0ffc98479d972f83b31a8735ce",
            "ea7d776b510349839e1c223eb59ed975",
            "43be9df75b9942dd9b94b2c7c5a0ed65",
            "991ff16f353447bb95a49742e0466259",
            "a9b17419d8084c57ac9ae8bd6d8938be",
            "3619ead1da764c19b5bfbe1af6f33d5d",
            "3aa9625c13b64947b3ce994b15e70bd3",
            "f6e599bb3b634069b2b0d2a6b2081746",
            "cf7eebe9cc4e4625b03e2758d25d5381",
            "fafa8b55ad4941ccbdbe733e88e9794a",
            "6258d9f4e0264b578e43e7f1f57577b8",
            "3f61ec011a844e1b859e5d0e4d5e481e",
            "cc1a663763eb4082a791a0431eb44794",
            "11e7242dab3841379e6069b00846b8f7",
            "8b0762c3136040b59817774257e30d2f",
            "d734e8b9f79943928609b58d85dd0bc1",
            "3383c54363454af49b55564721e22667",
            "05dab2ca7a3945358bcdaa9a92a7c07a",
            "5aa7663d574347638231eda589c554ad",
            "4624fce8659342738b9b44a30bd77bc6",
            "ef4562473fbb4b1f969978aaf342f395",
            "136bb8d0d08f419ab9ab22dab092ca32",
            "fe7dbe185fdf435e93254877507d1f05",
            "91c736bd8d6e47efaab52f859e46d6bf",
            "ce3cf60a077d435ca2d796ef581da563",
            "36075862c2c342389ea1c899d410037e",
            "f7438ed1cb3d467cb0410b926b9badae",
            "f2affab38fba4c41ac1e98823cbe6825",
            "ac55e8fdb7314f278a76d0f3081e871d",
            "00ac0b6469ec4d909cee465aa90b199b"
          ]
        },
        "id": "LtLyFX9gt-bM",
        "outputId": "ebf2ece1-9230-40c4-ef6c-89e8de786ab7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f40ceb9706b48c2945386766f72050b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:evaluate_modules.metrics.evaluate-measurement--toxicity.2390290fa0bf6d78480143547c6b08f3d4f8805b249df8c7a8e80d0ce8e3778b.toxicity:Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12061ca69e724bccad2f896b27817458",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/816 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84b70dbbc3544a3a96805073aee3b4a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25d124021a544862b00d969180406d8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "638ec5ff2a6b43d78a0bcbaaa0a112fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf7eebe9cc4e4625b03e2758d25d5381",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4624fce8659342738b9b44a30bd77bc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Claude Response: MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It provides a framework for tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\n",
            "Claude Response: Apache Spark is an open-source distributed computing system used for big data processing and analysis. It provides an interface for programming entire clusters with implicit data parallelism and fault tolerance, making it highly efficient for handling large-scale data processing tasks.\n",
            "Average Toxicity: 0.0001410242693964392\n",
            "Average ARI Grade Level: 16.7\n",
            "Average Flesch-Kincaid Grade Level: 13.55\n",
            "            inputs                                       ground_truth  \\\n",
            "0  What is MLflow?  MLflow is an open-source platform for managing...   \n",
            "1   What is Spark?  Apache Spark is an open-source, distributed co...   \n",
            "\n",
            "                                     Claude_response  toxicity  \\\n",
            "0  MLflow is an open-source platform for managing...  0.000140   \n",
            "1  Apache Spark is an open-source distributed com...  0.000142   \n",
            "\n",
            "   ari_grade_level  flesch_kincaid_grade_level  \n",
            "0             15.7                        11.3  \n",
            "1             17.7                        15.8  \n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import string\n",
        "import evaluate  # For toxicity\n",
        "import textstat # For readability\n",
        "\n",
        "# 1. Set your Anthropic API key\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"  # Replace!\n",
        "\n",
        "# 2. Define your evaluation data\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "        \"ground_truth\": [\n",
        "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
        "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
        "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
        "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
        "            \"machine learning models.\",\n",
        "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
        "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
        "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
        "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
        "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
        "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define a function to interact with the Claude API\n",
        "def anthropic_model(prompt, system_prompt):\n",
        "    client = anthropic.Anthropic()\n",
        "    try:\n",
        "        message = client.messages.create(\n",
        "            model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "            max_tokens=1024,\n",
        "            system=system_prompt,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        return message.content[0].text\n",
        "    except anthropic.APIStatusError as e:\n",
        "        print(f\"Anthropic API Error: {e}\")\n",
        "        return None\n",
        "    except anthropic.RateLimitError as e:\n",
        "        print(f\"Rate limit exceeded. Waiting and retrying...\")\n",
        "        time.sleep(60)\n",
        "        return anthropic_model(prompt, system_prompt)  # Retry\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# 4. Initialize the toxicity metric and readability metrics\n",
        "toxicity_metric = evaluate.load(\"toxicity\", module_type=\"measurement\")\n",
        "\n",
        "\n",
        "# 5. Modify the evaluation loop to use the Claude API and calculate metrics\n",
        "with mlflow.start_run() as run:\n",
        "    system_prompt = \"Answer the following question in two sentences\"\n",
        "\n",
        "    # Create a new column with the Claude responses\n",
        "    responses = []\n",
        "    for i in range(len(eval_data)):\n",
        "        response = anthropic_model(eval_data[\"inputs\"][i], system_prompt)\n",
        "        responses.append(response)\n",
        "        print(f\"Claude Response: {response}\") # Print for debugging\n",
        "\n",
        "    eval_data[\"Claude_response\"] = responses\n",
        "\n",
        "    # 6. Evaluate the model (using custom evaluation logic and external metrics)\n",
        "    toxicity_scores = []\n",
        "    ari_scores = []\n",
        "    flesch_scores = []\n",
        "\n",
        "    for response in eval_data[\"Claude_response\"]:\n",
        "        if response is None:\n",
        "            toxicity_scores.append(None)\n",
        "            ari_scores.append(None)\n",
        "            flesch_scores.append(None)\n",
        "            continue # Skip evaluation if the response is None\n",
        "\n",
        "        # Calculate toxicity\n",
        "        toxicity_result = toxicity_metric.compute(predictions=[response])\n",
        "        toxicity_score = toxicity_result[\"toxicity\"][0] if toxicity_result[\"toxicity\"] else None  # Handle empty toxicity scores\n",
        "\n",
        "        toxicity_scores.append(toxicity_score)\n",
        "\n",
        "        # Calculate readability scores\n",
        "        ari_score = textstat.automated_readability_index(response)\n",
        "        flesch_score = textstat.flesch_kincaid_grade(response)\n",
        "        ari_scores.append(ari_score)\n",
        "        flesch_scores.append(flesch_score)\n",
        "\n",
        "\n",
        "    eval_data[\"toxicity\"] = toxicity_scores\n",
        "    eval_data[\"ari_grade_level\"] = ari_scores\n",
        "    eval_data[\"flesch_kincaid_grade_level\"] = flesch_scores\n",
        "\n",
        "    # 7. Log metrics to MLflow\n",
        "    # Handle None values when calculating the mean\n",
        "    avg_toxicity = eval_data[\"toxicity\"].dropna().mean() if eval_data[\"toxicity\"].notna().any() else None\n",
        "    avg_ari = eval_data[\"ari_grade_level\"].dropna().mean() if eval_data[\"ari_grade_level\"].notna().any() else None\n",
        "    avg_flesch = eval_data[\"flesch_kincaid_grade_level\"].dropna().mean() if eval_data[\"flesch_kincaid_grade_level\"].notna().any() else None\n",
        "\n",
        "\n",
        "    if avg_toxicity is not None:\n",
        "        mlflow.log_metric(\"avg_toxicity\", avg_toxicity)\n",
        "    if avg_ari is not None:\n",
        "        mlflow.log_metric(\"avg_ari_grade_level\", avg_ari)\n",
        "    if avg_flesch is not None:\n",
        "        mlflow.log_metric(\"avg_flesch_kincaid_grade_level\", avg_flesch)\n",
        "\n",
        "    print(f\"Average Toxicity: {avg_toxicity}\")\n",
        "    print(f\"Average ARI Grade Level: {avg_ari}\")\n",
        "    print(f\"Average Flesch-Kincaid Grade Level: {avg_flesch}\")\n",
        "\n",
        "    print(eval_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBkRS4RdxBJG"
      },
      "source": [
        "Use a Custom List of Metrics\n",
        "Using the pre-defined metrics associated with a given model type is not the only way to generate scoring metrics for LLM evaluation in MLflow. You can specify a custom list of metrics in the extra_metrics argument in mlflow.evaluate:\n",
        "\n",
        "To add additional metrics to the default metrics list of pre-defined model type, keep the model_type and add your metrics to extra_metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KWitUaPugkT",
        "outputId": "d65a9626-c0dd-4771-c51c-9ae3acd65dc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:evaluate_modules.metrics.evaluate-measurement--toxicity.2390290fa0bf6d78480143547c6b08f3d4f8805b249df8c7a8e80d0ce8e3778b.toxicity:Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Claude Response: MLflow is an open source platform for managing the end-to-end machine learning lifecycle. It provides a set of tools and APIs for tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\n",
            "Latency: 2.066497802734375\n",
            "Claude Response: Apache Spark is an open-source distributed computing system used for big data processing and analysis. It provides an interface for programming entire clusters with implicit data parallelism and fault tolerance, making it highly efficient for handling large-scale data processing tasks.\n",
            "Latency: 2.3018925189971924\n",
            "Average Toxicity: 0.00014017869398230687\n",
            "Average ARI Grade Level: 15.6\n",
            "Average Flesch-Kincaid Grade Level: 13.45\n",
            "Average Latency: 2.1841951608657837\n",
            "            inputs                                       ground_truth  \\\n",
            "0  What is MLflow?  MLflow is an open-source platform for managing...   \n",
            "1   What is Spark?  Apache Spark is an open-source, distributed co...   \n",
            "\n",
            "                                     Claude_response   latency  toxicity  \\\n",
            "0  MLflow is an open source platform for managing...  2.066498  0.000139   \n",
            "1  Apache Spark is an open-source distributed com...  2.301893  0.000142   \n",
            "\n",
            "   ari_grade_level  flesch_kincaid_grade_level  \n",
            "0             13.5                        11.1  \n",
            "1             17.7                        15.8  \n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import string\n",
        "import evaluate  # For toxicity\n",
        "import textstat # For readability\n",
        "import numpy as np\n",
        "\n",
        "# 1. Set your Anthropic API key\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"  # Replace!\n",
        "\n",
        "# 2. Define your evaluation data\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "        \"ground_truth\": [\n",
        "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
        "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
        "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
        "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
        "            \"machine learning models.\",\n",
        "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
        "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
        "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
        "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
        "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
        "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define a function to interact with the Claude API\n",
        "def anthropic_model(prompt, system_prompt):\n",
        "    client = anthropic.Anthropic()\n",
        "    start_time = time.time()  # Capture start time\n",
        "    try:\n",
        "        message = client.messages.create(\n",
        "            model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "            max_tokens=1024,\n",
        "            system=system_prompt,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        response = message.content[0].text\n",
        "        end_time = time.time()  # Capture end time\n",
        "        return response, end_time - start_time # Return response and latency\n",
        "    except anthropic.APIStatusError as e:\n",
        "        print(f\"Anthropic API Error: {e}\")\n",
        "        return None, None  # Return None response and latency\n",
        "    except anthropic.RateLimitError as e:\n",
        "        print(f\"Rate limit exceeded. Waiting and retrying...\")\n",
        "        time.sleep(60)\n",
        "        return anthropic_model(prompt, system_prompt)  # Retry\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# 4. Initialize the toxicity metric and readability metrics\n",
        "toxicity_metric = evaluate.load(\"toxicity\", module_type=\"measurement\")\n",
        "\n",
        "# 5. Modify the evaluation loop to use the Claude API and calculate metrics\n",
        "with mlflow.start_run() as run:\n",
        "    system_prompt = \"Answer the following question in two sentences\"\n",
        "\n",
        "    # Create a new column with the Claude responses\n",
        "    responses = []\n",
        "    latencies = []  # List to store latency values\n",
        "    for i in range(len(eval_data)):\n",
        "        response, latency = anthropic_model(eval_data[\"inputs\"][i], system_prompt) #capture two values\n",
        "        responses.append(response)\n",
        "        latencies.append(latency)\n",
        "        print(f\"Claude Response: {response}\")  # Print for debugging\n",
        "        print(f\"Latency: {latency}\")\n",
        "\n",
        "    eval_data[\"Claude_response\"] = responses\n",
        "    eval_data[\"latency\"] = latencies #store latency in df\n",
        "\n",
        "    # 6. Evaluate the model (using custom evaluation logic and external metrics)\n",
        "    toxicity_scores = []\n",
        "    ari_scores = []\n",
        "    flesch_scores = []\n",
        "\n",
        "    for response in eval_data[\"Claude_response\"]:\n",
        "        if response is None:\n",
        "            toxicity_scores.append(None)\n",
        "            ari_scores.append(None)\n",
        "            flesch_scores.append(None)\n",
        "            continue # Skip evaluation if the response is None\n",
        "\n",
        "        # Calculate toxicity\n",
        "        toxicity_result = toxicity_metric.compute(predictions=[response])\n",
        "        toxicity_score = toxicity_result[\"toxicity\"][0] if toxicity_result[\"toxicity\"] else None  # Handle empty toxicity scores\n",
        "\n",
        "        toxicity_scores.append(toxicity_score)\n",
        "\n",
        "        # Calculate readability scores\n",
        "        ari_score = textstat.automated_readability_index(response)\n",
        "        flesch_score = textstat.flesch_kincaid_grade(response)\n",
        "        ari_scores.append(ari_score)\n",
        "        flesch_scores.append(flesch_score)\n",
        "\n",
        "\n",
        "    eval_data[\"toxicity\"] = toxicity_scores\n",
        "    eval_data[\"ari_grade_level\"] = ari_scores\n",
        "    eval_data[\"flesch_kincaid_grade_level\"] = flesch_scores\n",
        "\n",
        "    # 7. Log metrics to MLflow\n",
        "\n",
        "    # Handle None values when calculating the mean\n",
        "    avg_toxicity = eval_data[\"toxicity\"].dropna().mean() if eval_data[\"toxicity\"].notna().any() else None\n",
        "    avg_ari = eval_data[\"ari_grade_level\"].dropna().mean() if eval_data[\"ari_grade_level\"].notna().any() else None\n",
        "    avg_flesch = eval_data[\"flesch_kincaid_grade_level\"].dropna().mean() if eval_data[\"flesch_kincaid_grade_level\"].notna().any() else None\n",
        "    avg_latency = eval_data[\"latency\"].dropna().mean() if eval_data[\"latency\"].notna().any() else None\n",
        "\n",
        "\n",
        "    if avg_toxicity is not None:\n",
        "        mlflow.log_metric(\"avg_toxicity\", avg_toxicity)\n",
        "    if avg_ari is not None:\n",
        "        mlflow.log_metric(\"avg_ari_grade_level\", avg_ari)\n",
        "    if avg_flesch is not None:\n",
        "        mlflow.log_metric(\"avg_flesch_kincaid_grade_level\", avg_flesch)\n",
        "    if avg_latency is not None:\n",
        "        mlflow.log_metric(\"avg_latency\", avg_latency)\n",
        "\n",
        "\n",
        "    print(f\"Average Toxicity: {avg_toxicity}\")\n",
        "    print(f\"Average ARI Grade Level: {avg_ari}\")\n",
        "    print(f\"Average Flesch-Kincaid Grade Level: {avg_flesch}\")\n",
        "    print(f\"Average Latency: {avg_latency}\") # print average latency\n",
        "\n",
        "    print(eval_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVO-CYLGxUzl"
      },
      "source": [
        "To disable default metric calculation and only calculate your selected metrics, remove the model_type argument and define the desired metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1SJ8oY4u63m",
        "outputId": "e5092db6-9663-4bf5-c890-04702791f8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: What is MLflow?, Latency: 2.091501235961914\n",
            "Prompt: What is Spark?, Latency: 2.27738356590271\n",
            "Average Latency: 2.184442400932312\n",
            "            inputs   latency\n",
            "0  What is MLflow?  2.091501\n",
            "1   What is Spark?  2.277384\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np  # Import numpy\n",
        "\n",
        "# 1. Set your Anthropic API key\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"  # Replace!\n",
        "\n",
        "# 2. Define your evaluation data (you can adjust this as needed)\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define a function to interact with the Claude API and measure latency\n",
        "def anthropic_model(prompt, system_prompt):\n",
        "    client = anthropic.Anthropic()\n",
        "    start_time = time.time()  # Capture start time\n",
        "    try:\n",
        "        message = client.messages.create(\n",
        "            model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "            max_tokens=1024,\n",
        "            system=system_prompt,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        end_time = time.time()  # Capture end time\n",
        "        latency = end_time - start_time  # Calculate latency\n",
        "        return latency\n",
        "    except anthropic.APIStatusError as e:\n",
        "        print(f\"Anthropic API Error: {e}\")\n",
        "        return None  # Return None if there's an error\n",
        "    except anthropic.RateLimitError as e:\n",
        "        print(f\"Rate limit exceeded. Waiting and retrying...\")\n",
        "        time.sleep(60)\n",
        "        return anthropic_model(prompt, system_prompt)  # Retry\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# 4. Evaluate latency\n",
        "with mlflow.start_run() as run:\n",
        "    system_prompt = \"Answer the following question in two sentences\" #define the system prompt\n",
        "\n",
        "    latencies = []\n",
        "    for prompt in eval_data[\"inputs\"]:\n",
        "        latency = anthropic_model(prompt, system_prompt)\n",
        "        latencies.append(latency)\n",
        "        print(f\"Prompt: {prompt}, Latency: {latency}\")\n",
        "\n",
        "    eval_data[\"latency\"] = latencies  # Add latency to eval_data DataFrame\n",
        "    # Handle None values when calculating the mean and use only notna values.\n",
        "    avg_latency = eval_data[\"latency\"].dropna().mean() if eval_data[\"latency\"].notna().any() else None\n",
        "\n",
        "    if avg_latency is not None:\n",
        "        mlflow.log_metric(\"avg_latency\", avg_latency)\n",
        "        print(f\"Average Latency: {avg_latency}\")\n",
        "    else:\n",
        "        print(\"No successful API calls to calculate average latency.\")\n",
        "\n",
        "    print(eval_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FvPwfsjAgaq",
        "outputId": "b79cf8fd-ea23-403b-e240-5334cdadd799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (2.20.3)\n",
            "Requirement already satisfied: mlflow-skinny==2.20.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.20.3)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (0.44.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.20.3->mlflow) (4.12.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (2.38.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.3->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (0.37b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.3->mlflow) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.3->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY1bhlj_xaz9"
      },
      "source": [
        "###LLM-as-a-Judge Metrics\n",
        "LLM-as-a-Judge is a new type of metric that uses LLMs to score the quality of model outputs, providing a more human-like evaluation for complex language tasks while being more scalable and cost-effective than human evaluation.\n",
        "\n",
        "MLflow supports several builtin LLM-as-a-judge metrics, as well as allowing you to create your own LLM-as-a-judge metrics with custom configurations and prompts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ter_4Zgax_Gm"
      },
      "source": [
        "###Selecting the Judge Model\n",
        "By default, MLflow will use OpenAI’s GPT-4 model as the judge model that scores metrics. You can change the judge model by passing an override to the model argument within the metric definition.\n",
        "\n",
        "1. SaaS LLM Providers\n",
        "To use SaaS LLM providers, such as OpenAI or Anthropic, set the model parameter in the metrics definition, in the format of <provider>:/<model-name>. Currently, MLflow supports [\"openai\", \"anthropic\", \"bedrock\", \"mistral\", \"togetherai\"] as viable LLM providers for any judge model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKagiC6MyIei"
      },
      "source": [
        "Anthropic models can be accessed via the anthropic:/<model-name> URI. Note that the default judge parameters <#overriding-default-judge-parameters> need to be overridden by passing the parameters argument to the metrics definition, since the default parameters violates the Anthropic endpoint requirement (temperature and top_p cannot be specified together)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "b6e38e5c622b420db4dfda38665fd8f4",
            "79c95fd7d8e14ff78e61cf59fa00437d",
            "67745a44d08c4bd0aa6532e8c2cad67c",
            "16f4cfef764b444bb3c9c46531d27aac",
            "41963b7d46224ea4abbc27fc864373f9",
            "61c94e61b7154d7581a85eb42be9eb29",
            "2034d891cdbd4a0aa94f16728d6daa8c",
            "b049209dc4a14025955e9c55326cc1a4",
            "6c64bdb95c8f409b9da2ead96e3da851",
            "2b87f6ee8df44489b3fa3bc092e393cd",
            "73d21c37af80427494ef33a3b12c0a4f"
          ]
        },
        "id": "LeH2r9CE_eU6",
        "outputId": "f6d0e322-4db4-4d77-8976-56ed4f456aee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6e38e5c622b420db4dfda38665fd8f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "MetricValue(scores=[1], justifications=['The output is completely incorrect and contradicts the provided targets. The model describes MLflow as \"an innovative full self-driving airship,\" which has no relation to the actual definition provided in the targets stating that MLflow is \"an open-source platform for managing the end-to-end ML lifecycle.\" This response shows no semantic similarity to the correct information and provides entirely false information.'], aggregate_results={'mean': 1.0, 'variance': 0.0, 'p90': 1.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import mlflow\n",
        "import os\n",
        "\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"\n",
        "\n",
        "answer_correctness = mlflow.metrics.genai.answer_correctness(\n",
        "    model=\"anthropic:/claude-3-5-sonnet-20241022\",\n",
        "    # Override default judge parameters to meet Claude endpoint requirements.\n",
        "    parameters={\"temperature\": 0, \"max_tokens\": 256},\n",
        ")\n",
        "\n",
        "# Test the metric definition\n",
        "answer_correctness(\n",
        "    inputs=\"What is MLflow?\",\n",
        "    predictions=\"MLflow is an innovative full self-driving airship.\",\n",
        "    targets=\"MLflow is an open-source platform for managing the end-to-end ML lifecycle.\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69heOJHRzJCV"
      },
      "source": [
        "###Creating Custom LLM-as-a-Judge Metrics\n",
        "You can also create your own LLM-as-a-Judge evaluation metrics with mlflow.metrics.genai.make_genai_metric() API, which needs the following information:\n",
        "\n",
        "name: the name of your custom metric.\n",
        "\n",
        "definition: describe what’s the metric doing.\n",
        "\n",
        "grading_prompt: describe the scoring criteria.\n",
        "\n",
        "examples (Optional): a few input/output examples with scores provided; used as a reference for the LLM judge.\n",
        "\n",
        "See the API documentation for the full list of the configurations.\n",
        "\n",
        "Under the hood, definition, grading_prompt, examples together with evaluation data and model output will be composed into a long prompt and sent to LLM. If you are familiar with the concept of prompt engineering, SaaS LLM evaluation metric is basically trying to compose a “right” prompt containing instructions, data and model output so that LLM, e.g., GPT4 can output the information we want.\n",
        "\n",
        "Now let’s create a custom GenAI metrics called “professionalism”, which measures how professional our model output is.\n",
        "\n",
        "Let’s first create a few examples with scores, these will be the reference samples LLM judge uses. To create such examples, we will use mlflow.metrics.genai.EvaluationExample() class, which has 4 fields:\n",
        "\n",
        "input: input text.\n",
        "\n",
        "output: output text.\n",
        "\n",
        "score: the score for output in the context of input.\n",
        "\n",
        "justification: why do we give the score for the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hSVK-FqACnb7",
        "outputId": "80f3db9f-7821-435f-c58f-463cdf0f2df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google AI Studio Model: MLflow is an open-source platform designed to manage the entire machine learning (ML) lifecycle.  It's not tied to a specific ML library or programming language, making it a versatile tool for individuals and teams working on diverse projects.  Essentially, it helps organize and track experiments, reproduce results, and deploy models.\n",
            "\n",
            "Here's a breakdown of its core components:\n",
            "\n",
            "* **MLflow Tracking:**  This component allows you to log and query experiments, including parameters, code versions, metrics, and output files.  You can visualize these results in a user-friendly interface to compare different runs and identify the best-performing models.  Think of it as a detailed history of your ML work.\n",
            "\n",
            "* **MLflow Projects:**  This component provides a standard format for packaging reusable ML code.  It simplifies sharing and reproducing experiments by defining dependencies and entry points.  You can run these projects using various execution environments, ensuring consistency across different platforms.\n",
            "\n",
            "* **MLflow Models:**  This component provides a standard format for packaging ML models for various deployment scenarios.  Whether you're deploying to cloud platforms, mobile apps, or embedded systems, MLflow Models offers a unified way to save and load your models. It supports a wide range of flavors (e.g., TensorFlow, PyTorch, scikit-learn) and deployment targets (e.g., REST API, Docker container).\n",
            "\n",
            "* **MLflow Registry:**  This component provides a centralized model store to manage the lifecycle of your MLflow Models. You can version, stage, and deploy models in a collaborative environment, facilitating model governance and promoting reproducibility.  This is particularly useful for teams working on production-level ML systems.\n",
            "\n",
            "**Key Benefits of using MLflow:**\n",
            "\n",
            "* **Experiment Tracking:**  Keeps a comprehensive record of your experiments, enabling easy comparison and analysis.\n",
            "* **Reproducibility:**  Facilitates recreating past results by capturing all relevant information, including code, data, and parameters.\n",
            "* **Collaboration:**  Supports team collaboration by providing a central platform for sharing experiments and models.\n",
            "* **Deployment Flexibility:**  Simplifies deploying models to various platforms and environments.\n",
            "* **Model Management:**  Provides tools for versioning, staging, and deploying models in a controlled manner.\n",
            "* **Open Source and Extensible:**  Benefits from community support and can be extended to integrate with other tools.\n",
            "\n",
            "**In summary:** MLflow helps manage the chaos often associated with ML development by providing a structured approach to experimentation, reproducibility, and deployment. Whether you're a solo data scientist or part of a large team, MLflow can significantly streamline your workflow and improve the quality of your ML work.\n",
            "\n",
            "Google AI Studio Model: Apache Spark is a fast, in-memory data processing engine with elegant and expressive development APIs to allow data workers to efficiently execute streaming, machine learning, or SQL workloads that require fast iterative access to datasets. \n",
            "\n",
            "Here's a breakdown of key aspects:\n",
            "\n",
            "* **Fast and In-Memory Processing:** Spark's core strength lies in its ability to perform computations in memory.  It can cache intermediate data in memory across iterations, drastically reducing the I/O overhead compared to disk-based systems like Hadoop MapReduce. This makes it significantly faster for iterative algorithms and interactive data analysis.\n",
            "\n",
            "* **Unified Analytics Engine:**  Spark offers a unified platform for diverse workloads. You can use it for batch processing, real-time stream processing, machine learning, and graph processing, all within the same framework. This simplifies development and deployment.\n",
            "\n",
            "* **Elegant and Expressive APIs:** Spark provides easy-to-use APIs in Java, Scala, Python, R, and SQL. These APIs allow developers to express complex data transformations and analyses concisely.\n",
            "\n",
            "* **Scalability and Fault Tolerance:** Spark is designed for distributed computing and can handle massive datasets across clusters of computers. It also incorporates fault tolerance mechanisms to ensure data reliability and processing continuity.\n",
            "\n",
            "* **Open-Source and Active Community:**  Spark is an open-source project with a large and active community, contributing to its continuous improvement and providing ample resources and support for users.\n",
            "\n",
            "**Key Components of Spark:**\n",
            "\n",
            "* **Spark Core:** The foundation of Spark, providing distributed task dispatching, scheduling, and basic I/O functionalities.\n",
            "* **Spark SQL:** Allows querying data using SQL and integrates with Hive.\n",
            "* **Spark Streaming:** Enables real-time processing of data streams.\n",
            "* **MLlib (Machine Learning Library):**  Provides a library of machine learning algorithms.\n",
            "* **GraphX:**  Facilitates graph processing and analysis.\n",
            "\n",
            "**How Spark Works:**\n",
            "\n",
            "Spark applications run as independent sets of processes on a cluster, coordinated by the *SparkSession* object in the driver program.  The driver program breaks down the computation into tasks that are executed by *executors* across the cluster.  The key concept is the *Resilient Distributed Dataset (RDD)*, a collection of elements partitioned across the nodes of the cluster that can be operated on in parallel. Spark also introduces *DataFrames* and *Datasets* which provide a higher-level abstraction and optimization capabilities compared to RDDs.\n",
            "\n",
            "**Use Cases:**\n",
            "\n",
            "Spark is used in a wide range of applications, including:\n",
            "\n",
            "* **Data ETL (Extract, Transform, Load):** Cleaning and preparing data for analysis.\n",
            "* **Real-time analytics:** Processing streaming data from sensors, social media, etc.\n",
            "* **Machine learning:** Training and deploying machine learning models.\n",
            "* **Graph processing:** Analyzing social networks, recommendation systems, etc.\n",
            "* **Log processing:** Analyzing large volumes of log data.\n",
            "\n",
            "\n",
            "In summary, Spark's speed, ease of use, and versatility make it a powerful tool for large-scale data processing and analysis across various domains.\n",
            "\n",
            "Detailed Evaluation Results:\n",
            "Question: What is MLflow?\n",
            "Answer: MLflow is an open-source platform designed to manage the entire machine learning (ML) lifecycle.  It's not tied to a specific ML library or programming language, making it a versatile tool for individuals and teams working on diverse projects.  Essentially, it helps organize and track experiments, reproduce results, and deploy models.\n",
            "\n",
            "Here's a breakdown of its core components:\n",
            "\n",
            "* **MLflow Tracking:**  This component allows you to log and query experiments, including parameters, code versions, metrics, and output files.  You can visualize these results in a user-friendly interface to compare different runs and identify the best-performing models.  Think of it as a detailed history of your ML work.\n",
            "\n",
            "* **MLflow Projects:**  This component provides a standard format for packaging reusable ML code.  It simplifies sharing and reproducing experiments by defining dependencies and entry points.  You can run these projects using various execution environments, ensuring consistency across different platforms.\n",
            "\n",
            "* **MLflow Models:**  This component provides a standard format for packaging ML models for various deployment scenarios.  Whether you're deploying to cloud platforms, mobile apps, or embedded systems, MLflow Models offers a unified way to save and load your models. It supports a wide range of flavors (e.g., TensorFlow, PyTorch, scikit-learn) and deployment targets (e.g., REST API, Docker container).\n",
            "\n",
            "* **MLflow Registry:**  This component provides a centralized model store to manage the lifecycle of your MLflow Models. You can version, stage, and deploy models in a collaborative environment, facilitating model governance and promoting reproducibility.  This is particularly useful for teams working on production-level ML systems.\n",
            "\n",
            "**Key Benefits of using MLflow:**\n",
            "\n",
            "* **Experiment Tracking:**  Keeps a comprehensive record of your experiments, enabling easy comparison and analysis.\n",
            "* **Reproducibility:**  Facilitates recreating past results by capturing all relevant information, including code, data, and parameters.\n",
            "* **Collaboration:**  Supports team collaboration by providing a central platform for sharing experiments and models.\n",
            "* **Deployment Flexibility:**  Simplifies deploying models to various platforms and environments.\n",
            "* **Model Management:**  Provides tools for versioning, staging, and deploying models in a controlled manner.\n",
            "* **Open Source and Extensible:**  Benefits from community support and can be extended to integrate with other tools.\n",
            "\n",
            "**In summary:** MLflow helps manage the chaos often associated with ML development by providing a structured approach to experimentation, reproducibility, and deployment. Whether you're a solo data scientist or part of a large team, MLflow can significantly streamline your workflow and improve the quality of your ML work.\n",
            "\n",
            "Score: 5\n",
            "Justification: The answer provides a comprehensive and accurate explanation of MLflow, covering its core components, key benefits, and role in managing the machine learning lifecycle. The information presented is factually correct and consistent with the common understanding of MLflow in the data science community. The answer addresses the question completely, offering a detailed breakdown of MLflow's features and their significance. Moreover, the answer is well-structured, clear, and easy to understand, even for readers who may not have prior knowledge of MLflow. The use of bullet points and bold formatting enhances readability and helps highlight important aspects. Overall, this is an excellent answer that effectively communicates what MLflow is and why it is valuable in machine learning projects.\n",
            "---\n",
            "Question: What is Spark?\n",
            "Answer: Apache Spark is a fast, in-memory data processing engine with elegant and expressive development APIs to allow data workers to efficiently execute streaming, machine learning, or SQL workloads that require fast iterative access to datasets. \n",
            "\n",
            "Here's a breakdown of key aspects:\n",
            "\n",
            "* **Fast and In-Memory Processing:** Spark's core strength lies in its ability to perform computations in memory.  It can cache intermediate data in memory across iterations, drastically reducing the I/O overhead compared to disk-based systems like Hadoop MapReduce. This makes it significantly faster for iterative algorithms and interactive data analysis.\n",
            "\n",
            "* **Unified Analytics Engine:**  Spark offers a unified platform for diverse workloads. You can use it for batch processing, real-time stream processing, machine learning, and graph processing, all within the same framework. This simplifies development and deployment.\n",
            "\n",
            "* **Elegant and Expressive APIs:** Spark provides easy-to-use APIs in Java, Scala, Python, R, and SQL. These APIs allow developers to express complex data transformations and analyses concisely.\n",
            "\n",
            "* **Scalability and Fault Tolerance:** Spark is designed for distributed computing and can handle massive datasets across clusters of computers. It also incorporates fault tolerance mechanisms to ensure data reliability and processing continuity.\n",
            "\n",
            "* **Open-Source and Active Community:**  Spark is an open-source project with a large and active community, contributing to its continuous improvement and providing ample resources and support for users.\n",
            "\n",
            "**Key Components of Spark:**\n",
            "\n",
            "* **Spark Core:** The foundation of Spark, providing distributed task dispatching, scheduling, and basic I/O functionalities.\n",
            "* **Spark SQL:** Allows querying data using SQL and integrates with Hive.\n",
            "* **Spark Streaming:** Enables real-time processing of data streams.\n",
            "* **MLlib (Machine Learning Library):**  Provides a library of machine learning algorithms.\n",
            "* **GraphX:**  Facilitates graph processing and analysis.\n",
            "\n",
            "**How Spark Works:**\n",
            "\n",
            "Spark applications run as independent sets of processes on a cluster, coordinated by the *SparkSession* object in the driver program.  The driver program breaks down the computation into tasks that are executed by *executors* across the cluster.  The key concept is the *Resilient Distributed Dataset (RDD)*, a collection of elements partitioned across the nodes of the cluster that can be operated on in parallel. Spark also introduces *DataFrames* and *Datasets* which provide a higher-level abstraction and optimization capabilities compared to RDDs.\n",
            "\n",
            "**Use Cases:**\n",
            "\n",
            "Spark is used in a wide range of applications, including:\n",
            "\n",
            "* **Data ETL (Extract, Transform, Load):** Cleaning and preparing data for analysis.\n",
            "* **Real-time analytics:** Processing streaming data from sensors, social media, etc.\n",
            "* **Machine learning:** Training and deploying machine learning models.\n",
            "* **Graph processing:** Analyzing social networks, recommendation systems, etc.\n",
            "* **Log processing:** Analyzing large volumes of log data.\n",
            "\n",
            "\n",
            "In summary, Spark's speed, ease of use, and versatility make it a powerful tool for large-scale data processing and analysis across various domains.\n",
            "\n",
            "Score: 5\n",
            "Justification: The answer provides a comprehensive and accurate explanation of Apache Spark. It covers key aspects such as Spark's ability to perform fast, in-memory processing, its unified analytics engine, elegant APIs, scalability, and fault tolerance. The answer also mentions Spark's open-source nature and active community. It further breaks down the key components of Spark and explains how Spark works using concepts like SparkSession, executors, and RDDs. Finally, it lists several common use cases for Spark. The answer is well-structured, clear, and easy to understand, making it an excellent response to the question \"What is Spark?\". The information provided is factually correct and consistent with common knowledge about Apache Spark.\n",
            "---\n",
            "Average Answer Correctness from Claude: 5.0\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from mlflow.metrics import make_metric, MetricValue\n",
        "import re\n",
        "\n",
        "# 1. Set your API keys\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"  # Replace!\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \".\" # Replace with google api key!\n",
        "GOOGLE_API_KEY=os.environ[\"GOOGLE_API_KEY\"]\n",
        "# Configure the Google API\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "\n",
        "# 2. Define your models\n",
        "claude_model_id = \"claude-3-opus-20240229\"  # Replace!  Check what models are available\n",
        "google_model_id = \"gemini-1.5-pro-latest\"  # Replace! Check what models are available\n",
        "\n",
        "# 3. Define your evaluation data\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 4. Set the global evaluation prompt\n",
        "evaluation_prompt = \"\"\"You are an expert evaluator assessing the quality of an answer to a question.\n",
        "\n",
        "    Question: {question}\n",
        "    Answer: {answer}\n",
        "\n",
        "    Assess the answer based on the following criteria:\n",
        "\n",
        "    - Is the answer factually correct and consistent with common knowledge?\n",
        "    - Does the answer address the question completely and accurately?\n",
        "    - Is the answer well-written, clear, and easy to understand?\n",
        "\n",
        "    Provide a score from 1 to 5 and a justification, following the exact format:\n",
        "\n",
        "    Score: [your score]\n",
        "    Justification: [your justification]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# 5. All custom functions for the evaluation metrics\n",
        "def get_google_ai_studio_response(prompt, google_model_id):\n",
        "    \"\"\"Calls Google AI Studio and returns the text response or None on error.\"\"\"\n",
        "    model = genai.GenerativeModel(google_model_id)\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Google Generative AI Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_claude_judgment(question, answer, prompt, claude_model_id):\n",
        "    \"\"\"Calls Claude API for evaluation and returns a tuple (score, justification) or (1, \"Error\") on error.\"\"\"\n",
        "    try:\n",
        "        client = anthropic.Anthropic()\n",
        "        message = client.messages.create(\n",
        "            model=claude_model_id,\n",
        "            max_tokens=300,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt.format(question=question, answer=answer)}],\n",
        "        )\n",
        "        claude_response = message.content[0].text\n",
        "\n",
        "        # Use regular expressions to extract the score and justification\n",
        "        match = re.search(r\"Score:\\s*(\\d+)\\s*Justification:\\s*(.+)\", claude_response, re.DOTALL) #Extract the data\n",
        "\n",
        "        if match:\n",
        "            score = int(match.group(1))\n",
        "            justification = match.group(2).strip()\n",
        "            return score, justification\n",
        "        else:\n",
        "            print(f\"Could not parse Claude's response: {claude_response}\")\n",
        "            return 1, \"Could not parse Claude's response.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling Claude API: {e}\")\n",
        "        return 1, \"Error during evaluation.\"  # Consistent return\n",
        "\n",
        "\n",
        "def claude_judge_eval_fn(predictions, inputs, claude_model_id):\n",
        "    \"\"\"Evaluates responses using Claude, returns an MLflow MetricValue.\"\"\"\n",
        "    scores = []\n",
        "    justifications = []\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] is None:  # Handle potential None responses\n",
        "            scores.append(1)  # Assign lowest score if Google model returned None\n",
        "            justifications.append(\"Google model returned an error.\")\n",
        "            continue\n",
        "\n",
        "        question = inputs[i]\n",
        "        answer = predictions[i]\n",
        "\n",
        "        score, justification = get_claude_judgment(question=question, answer=answer, prompt=evaluation_prompt, claude_model_id=claude_model_id)\n",
        "        scores.append(score)\n",
        "        justifications.append(justification)\n",
        "\n",
        "    aggregate_results = {\n",
        "        \"mean_score\": sum(scores) / len(scores) if scores else 0,\n",
        "        #Add also the justification\n",
        "    }\n",
        "\n",
        "    # Log detailed results to console\n",
        "    print(\"Detailed Evaluation Results:\")\n",
        "    for i in range(len(inputs)):\n",
        "        print(f\"Question: {inputs[i]}\")\n",
        "        print(f\"Answer: {predictions[i]}\")\n",
        "        print(f\"Score: {scores[i]}\")\n",
        "        print(f\"Justification: {justifications[i]}\")\n",
        "        print(\"---\")\n",
        "\n",
        "\n",
        "    return MetricValue(scores=scores, aggregate_results=aggregate_results)\n",
        "\n",
        "\n",
        "\n",
        "# 6. Define custom evaluation metric\n",
        "claude_judge_metric = make_metric(\n",
        "    eval_fn=claude_judge_eval_fn,\n",
        "    greater_is_better=True,\n",
        "    name=\"claude_answer_correctness\",\n",
        ")\n",
        "\n",
        "# 7. All code connected in the execution\n",
        "with mlflow.start_run() as run:\n",
        "    # Generate Google Model responses\n",
        "    google_responses = []\n",
        "    for prompt in eval_data[\"inputs\"]:\n",
        "        response = get_google_ai_studio_response(prompt, google_model_id)\n",
        "        google_responses.append(response)\n",
        "        print(f\"Google AI Studio Model: {response}\")\n",
        "\n",
        "    # Evaluate using the custom metric\n",
        "    metric_value = claude_judge_metric(predictions=google_responses, inputs=eval_data[\"inputs\"], claude_model_id=claude_model_id)\n",
        "    avg_answer_correctness = metric_value.aggregate_results[\"mean_score\"]\n",
        "\n",
        "    # Log results\n",
        "    mlflow.log_metric(\"avg_answer_correctness\", avg_answer_correctness)\n",
        "\n",
        "    print(f\"Average Answer Correctness from Claude: {avg_answer_correctness}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_8y6PMjyOVW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "a47a1c2dc78e48e1bc34926aa9fc6baf",
            "390e574222b041479836a972c293c369",
            "d0b6533160e44952b80736c724053f17",
            "0231d2ea90904a9db9a015a9fb0148cd",
            "4eeae1ea45d444409be7632eeb763bb9",
            "a7b553469f224ce288024bc315e76da1",
            "d4de634483a94e70a5080bf454938542",
            "e124fbd133f040c581be2a6ad9f19d4c",
            "6d5c770b70b04186a71307368ed958df",
            "a61fc9b67f86491398580b5ad439903b",
            "9b13f5ca8b9a43e180adfce066b7395b",
            "c0fe423fdf914757acc260e8c277f785",
            "5515f572725642db831af8d9eeb71b88",
            "37486c608beb4f20986783656895adaa",
            "120994f8f5144079b5dad8eb594ff31c",
            "80b7dfb0d03f4ce18b13d21c8d13c1d1",
            "b2a94115cff14ea08c3f874da035975b",
            "2ae90e738a2a4e99a8746dd3b1a8142f",
            "59cbec65a310451abf74c2cff08f3d1f",
            "25219539aae6480f8a4da04908dc924e",
            "87a406a991df4e228d360a1e8121a30e",
            "225eef2cfe694cd8ba98ef6cc0c18d6c"
          ]
        },
        "id": "2Bqced9KKXh0",
        "outputId": "3748a4b0-1dde-4013-a1ab-f48c7c1da034"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 08:24:29 WARNING mlflow.models.evaluation.evaluators.default: Setting the latency to 0 for all entries because the model is not provided.\n",
            "2025/03/06 08:24:29 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a47a1c2dc78e48e1bc34926aa9fc6baf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:3787: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0fe423fdf914757acc260e8c277f785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from mlflow.metrics import latency\n",
        "from mlflow.metrics.genai import answer_correctness\n",
        "import pandas as pd #import pandas\n",
        "import anthropic # Import the anthropic library\n",
        "import os # Import the os library\n",
        "\n",
        "\n",
        "# 1. Set your Anthropic API key\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-\"  # Replace!\n",
        "\n",
        "# 2. Assuming your ground truth data is similar to how you defined it in previous cells\n",
        "eval_data = pd.DataFrame(\n",
        "    {\n",
        "        \"inputs\": [\n",
        "            \"What is MLflow?\",\n",
        "            \"What is Spark?\",\n",
        "        ],\n",
        "        \"ground_truth\": [\n",
        "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
        "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
        "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
        "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
        "            \"machine learning models.\",\n",
        "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
        "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
        "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
        "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
        "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
        "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Define a function to interact with the Claude API\n",
        "def anthropic_model(prompt, system_prompt=\"Answer the following question:\"): # Define a default system prompt\n",
        "    client = anthropic.Anthropic()\n",
        "    try:\n",
        "        message = client.messages.create(\n",
        "            model=\"claude-3-opus-20240229\",  # Replace with an available Claude model for you\n",
        "            max_tokens=1024,\n",
        "            system=system_prompt,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        return message.content[0].text\n",
        "    except anthropic.APIStatusError as e:\n",
        "        print(f\"Anthropic API Error: {e}\")\n",
        "        return None\n",
        "    except anthropic.RateLimitError as e:\n",
        "        print(f\"Rate limit exceeded. Waiting and retrying...\")\n",
        "        time.sleep(60)\n",
        "        return anthropic_model(prompt, system_prompt)  # Retry\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 4. Generate predictions using the Claude model\n",
        "eval_data[\"predictions\"] = eval_data[\"inputs\"].apply(anthropic_model) # Apply the model to the 'inputs' column\n",
        "\n",
        "\n",
        "results = mlflow.evaluate(\n",
        "    data=eval_data,  # Explicitly pass eval_data as the 'data' argument\n",
        "    targets=\"ground_truth\",\n",
        "    predictions=\"predictions\", # Specify the column containing model predictions\n",
        "    extra_metrics=[\n",
        "        answer_correctness(),\n",
        "        latency(),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVXSJYP6zy0i"
      },
      "source": [
        "##Prepare Your Target Models\n",
        "In order to evaluate your model with mlflow.evaluate(), your model has to be one of the following types:\n",
        "\n",
        "A mlflow.pyfunc.PyFuncModel() instance or a URI pointing to a logged mlflow.pyfunc.PyFuncModel model. In general we call that MLflow model. The\n",
        "\n",
        "A python function that takes in string inputs and outputs a single string. Your callable must match the signature of mlflow.pyfunc.PyFuncModel.predict() (without params argument), briefly it should:\n",
        "\n",
        "Has data as the only argument, which can be a pandas.Dataframe, numpy.ndarray, python list, dictionary or scipy matrix.\n",
        "\n",
        "Returns one of pandas.DataFrame, pandas.Series, numpy.ndarray or list.\n",
        "\n",
        "An MLflow Deployments endpoint URI pointing to a local MLflow AI Gateway, Databricks Foundation Models API, and External Models in Databricks Model Serving.\n",
        "\n",
        "Set model=None, and put model outputs in data. Only applicable when the data is a Pandas dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNtlfELQ0E9b"
      },
      "source": [
        "###Evaluating with an MLflow Model\n",
        "For detailed instruction on how to convert your model into a mlflow.pyfunc.PyFuncModel instance, please read this doc. But in short, to evaluate your model as an MLflow model, we recommend following the steps below:\n",
        "\n",
        "Log your model to MLflow server by log_model. Each flavor (opeanai, pytorch, …) has its own log_model API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSF0BqExkxyF",
        "outputId": "70adad43-6e9c-49a8-a90d-ac291d5fed97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/06 10:37:31 INFO mlflow.pyfunc: Inferring model signature from input example\n",
            "2025/03/06 10:37:40 INFO mlflow.models.model: Found the following environment variables used during model inference: [ANTHROPIC_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import anthropic\n",
        "import os\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "class ClaudeModelWrapper(mlflow.pyfunc.PythonModel):\n",
        "    \"\"\"\n",
        "    A custom MLflow model that wraps the Anthropic Claude API.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str, system_prompt: str):\n",
        "        self.model_name = model_name\n",
        "        self.system_prompt = system_prompt\n",
        "        self.anthropic_api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "\n",
        "    def load_context(self, context: mlflow.pyfunc.model.PythonModelContext) -> None:\n",
        "        \"\"\"Loads artifacts (none in this case).\"\"\"\n",
        "        if not self.anthropic_api_key:\n",
        "            raise ValueError(\"Anthropic API key not found. Set ANTHROPIC_API_KEY environment variable.\")\n",
        "\n",
        "    def predict(self, context: mlflow.pyfunc.model.PythonModelContext, model_input: pd.DataFrame) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generates predictions using the Claude API.\n",
        "\n",
        "        Args:\n",
        "            context: MLflow context (unused).\n",
        "            model_input: Pandas DataFrame with a 'question' column containing prompts.\n",
        "\n",
        "        Returns:\n",
        "            List of responses from Claude.\n",
        "        \"\"\"\n",
        "        client = anthropic.Anthropic()\n",
        "        responses = []\n",
        "        for question in model_input[\"question\"]:\n",
        "            try:\n",
        "                message = client.messages.create(\n",
        "                    model=self.model_name,\n",
        "                    max_tokens=1024,\n",
        "                    system = self.system_prompt,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": question}\n",
        "                    ],\n",
        "                )\n",
        "                responses.append(message.content[0].text)\n",
        "            except Exception as e:\n",
        "                print(f\"Error calling Claude API: {e}\")\n",
        "                responses.append(None)  # Or a suitable error value\n",
        "        return responses\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "claude_model_name = \"claude-3-opus-20240229\"  # Or an appropriate Claude model. Change the model with one that is accesible\n",
        "system_prompt = \"Answer the following question in two sentences.\"\n",
        "\n",
        "# Create and log the MLflow model\n",
        "with mlflow.start_run() as run:\n",
        "    claude_model = ClaudeModelWrapper(model_name=claude_model_name, system_prompt=system_prompt)\n",
        "    mlflow.pyfunc.log_model(\n",
        "        python_model=claude_model,\n",
        "        artifact_path=\"claude_model\",\n",
        "        input_example=pd.DataFrame({\"question\": [\"What is the capital of France?\"]}),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m59EoWU1wKm"
      },
      "source": [
        "logging into the MLflow UI in Google Colab requires a few steps because Colab runs in a remote environment. You can't directly access localhost from your local browser. Here's a breakdown of the steps:\n",
        "\n",
        "1: Using ngrok\n",
        "\n",
        "ngrok creates a secure tunnel from a public URL to your local machine. This is the generally recommended approach.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84UYfVlR29m9"
      },
      "source": [
        "Install ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6SQ2nAf437F",
        "outputId": "5cfadcd9-97f5-41e8-955f-96031940c5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j435zgM33AoS"
      },
      "source": [
        "Set the ngrok Authtoken:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhgMj2Th-dtU"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"\")  # Replace!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-88lx9l0NVE"
      },
      "source": [
        "Create the Tunnel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGiSpXs--w_R",
        "outputId": "d66adbdd-9cfb-4d3e-ae1d-1df18202bbe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow UI URL: https://1391-34-57-255-3.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "http_tunnel = ngrok.connect(addr=5000, proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow UI URL:\", http_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A4EUUT63SU4"
      },
      "source": [
        "Start the MLflow UI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDp0hzmW_lnT",
        "outputId": "b46cb8a0-e3fb-43aa-92b9-260400db38ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-07 04:56:42 +0000] [4658] [INFO] Starting gunicorn 23.0.0\n",
            "[2025-03-07 04:56:42 +0000] [4658] [INFO] Listening at: http://127.0.0.1:5000 (4658)\n",
            "[2025-03-07 04:56:42 +0000] [4658] [INFO] Using worker: sync\n",
            "[2025-03-07 04:56:42 +0000] [4659] [INFO] Booting worker with pid: 4659\n",
            "[2025-03-07 04:56:42 +0000] [4660] [INFO] Booting worker with pid: 4660\n",
            "[2025-03-07 04:56:42 +0000] [4661] [INFO] Booting worker with pid: 4661\n",
            "[2025-03-07 04:56:42 +0000] [4662] [INFO] Booting worker with pid: 4662\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 3656.76it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 4275.54it/s] \n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 2863.01it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 534.51it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 4419.71it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 985.04it/s] \n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 3563.55it/s] \n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1646.12it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 3688.92it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1249.05it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1589.96it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1317.72it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1610.10it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1712.66it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 3816.47it/s] \n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1713.36it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 3379.78it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1365.33it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1144.73it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1725.34it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 897.18it/s] \n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1246.82it/s]\n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 852.15it/s] \n",
            "Downloading artifacts: 100% 1/1 [00:00<00:00, 1285.81it/s]\n"
          ]
        }
      ],
      "source": [
        "!mlflow ui --port 5000 &"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPutCReU79RKyX4+plAXkHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ac0b6469ec4d909cee465aa90b199b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0231d2ea90904a9db9a015a9fb0148cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a61fc9b67f86491398580b5ad439903b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b13f5ca8b9a43e180adfce066b7395b",
            "value": " 1/1 [00:00&lt;00:00,  1.31it/s]"
          }
        },
        "05dab2ca7a3945358bcdaa9a92a7c07a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09bf686009ce464091955d269b42eec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eee4cbb64594125ba097ef895149332": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e7242dab3841379e6069b00846b8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12061ca69e724bccad2f896b27817458": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2338698c053d4a8ba97966dff3ff7ce4",
              "IPY_MODEL_b2a5991393fe4e5ea3ac4419250b7d10",
              "IPY_MODEL_4ca3c4d534e846c5b6e07773f55bd780"
            ],
            "layout": "IPY_MODEL_9380fd47c089424484129b412b6f8aaa"
          }
        },
        "120994f8f5144079b5dad8eb594ff31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a406a991df4e228d360a1e8121a30e",
            "placeholder": "​",
            "style": "IPY_MODEL_225eef2cfe694cd8ba98ef6cc0c18d6c",
            "value": " 2/2 [00:00&lt;00:00, 170.78it/s]"
          }
        },
        "136bb8d0d08f419ab9ab22dab092ca32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7438ed1cb3d467cb0410b926b9badae",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2affab38fba4c41ac1e98823cbe6825",
            "value": 239
          }
        },
        "148b35bf7abb45bfab48e616cd7fddc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287d8901f1e14572b140825c55450a56",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d972513c3e4d719632d13b8c8feeed",
            "value": " 1.11k/1.11k [00:00&lt;00:00, 63.7kB/s]"
          }
        },
        "16f4cfef764b444bb3c9c46531d27aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b87f6ee8df44489b3fa3bc092e393cd",
            "placeholder": "​",
            "style": "IPY_MODEL_73d21c37af80427494ef33a3b12c0a4f",
            "value": " 1/1 [00:02&lt;00:00,  2.73s/it]"
          }
        },
        "1708b949bc8244bdb1fc0708985f9b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed8ae9bb2fc4b06ae7051b584cb1fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_340980ff0da24d3aacde51ea337a6327",
            "value": " 6.08k/6.08k [00:00&lt;00:00, 283kB/s]"
          }
        },
        "1ed8ae9bb2fc4b06ae7051b584cb1fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2034d891cdbd4a0aa94f16728d6daa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "213a3e1df2a2458b8555fbb2f80764ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f184c39eae274e44a230a53916cabdce",
            "max": 1106,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9e4c250030b4c93b53594244723d7de",
            "value": 1106
          }
        },
        "225eef2cfe694cd8ba98ef6cc0c18d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2338698c053d4a8ba97966dff3ff7ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_255d966a606e4acf96b6bc3b3dfc4a20",
            "placeholder": "​",
            "style": "IPY_MODEL_afaabd1885c6416f95dbba4ec96540bb",
            "value": "config.json: 100%"
          }
        },
        "25219539aae6480f8a4da04908dc924e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "255d966a606e4acf96b6bc3b3dfc4a20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c532defe1647d892e1020963d01324": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d124021a544862b00d969180406d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8725c3887d34a9586dbff91898fcb4e",
              "IPY_MODEL_213a3e1df2a2458b8555fbb2f80764ac",
              "IPY_MODEL_148b35bf7abb45bfab48e616cd7fddc0"
            ],
            "layout": "IPY_MODEL_25c532defe1647d892e1020963d01324"
          }
        },
        "287d8901f1e14572b140825c55450a56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae90e738a2a4e99a8746dd3b1a8142f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b87f6ee8df44489b3fa3bc092e393cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3383c54363454af49b55564721e22667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33d7611f6d42497a8b3d693f725c7630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e651bc7d814967b1db88ec26b2493d",
            "placeholder": "​",
            "style": "IPY_MODEL_3bb59c69a0d346b49b1f66df9dca83e5",
            "value": "model.safetensors: 100%"
          }
        },
        "340980ff0da24d3aacde51ea337a6327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36075862c2c342389ea1c899d410037e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3619ead1da764c19b5bfbe1af6f33d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37486c608beb4f20986783656895adaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59cbec65a310451abf74c2cff08f3d1f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25219539aae6480f8a4da04908dc924e",
            "value": 2
          }
        },
        "390e574222b041479836a972c293c369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b553469f224ce288024bc315e76da1",
            "placeholder": "​",
            "style": "IPY_MODEL_d4de634483a94e70a5080bf454938542",
            "value": "100%"
          }
        },
        "3aa9625c13b64947b3ce994b15e70bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8f2da6455641b3bffb2a1a2eb7993a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb59c69a0d346b49b1f66df9dca83e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f61ec011a844e1b859e5d0e4d5e481e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05dab2ca7a3945358bcdaa9a92a7c07a",
            "placeholder": "​",
            "style": "IPY_MODEL_5aa7663d574347638231eda589c554ad",
            "value": " 456k/456k [00:00&lt;00:00, 19.3MB/s]"
          }
        },
        "41963b7d46224ea4abbc27fc864373f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43be9df75b9942dd9b94b2c7c5a0ed65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4624fce8659342738b9b44a30bd77bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef4562473fbb4b1f969978aaf342f395",
              "IPY_MODEL_136bb8d0d08f419ab9ab22dab092ca32",
              "IPY_MODEL_fe7dbe185fdf435e93254877507d1f05"
            ],
            "layout": "IPY_MODEL_91c736bd8d6e47efaab52f859e46d6bf"
          }
        },
        "4b93ab0ffc98479d972f83b31a8735ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aa9625c13b64947b3ce994b15e70bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6e599bb3b634069b2b0d2a6b2081746",
            "value": " 899k/899k [00:00&lt;00:00, 8.81MB/s]"
          }
        },
        "4ca3c4d534e846c5b6e07773f55bd780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3617d3da5f3429c86ce71dba891a651",
            "placeholder": "​",
            "style": "IPY_MODEL_b6d7f07d062646cca3ca3da576de50da",
            "value": " 816/816 [00:00&lt;00:00, 35.4kB/s]"
          }
        },
        "4eeae1ea45d444409be7632eeb763bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53586e54851f4464a5daef12409605aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad114a55cdae4d9b837f5b0f65a7939b",
            "placeholder": "​",
            "style": "IPY_MODEL_5defa7fea1f74fa48e3c11973593593a",
            "value": " 499M/499M [00:05&lt;00:00, 70.5MB/s]"
          }
        },
        "5515f572725642db831af8d9eeb71b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a94115cff14ea08c3f874da035975b",
            "placeholder": "​",
            "style": "IPY_MODEL_2ae90e738a2a4e99a8746dd3b1a8142f",
            "value": "100%"
          }
        },
        "59cbec65a310451abf74c2cff08f3d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa7663d574347638231eda589c554ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5defa7fea1f74fa48e3c11973593593a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61c94e61b7154d7581a85eb42be9eb29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6258d9f4e0264b578e43e7f1f57577b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d734e8b9f79943928609b58d85dd0bc1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3383c54363454af49b55564721e22667",
            "value": 456318
          }
        },
        "627706204c714b0f9adb90e4863a675a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638ec5ff2a6b43d78a0bcbaaa0a112fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91ae8a790b014246b39d7038c731ecb7",
              "IPY_MODEL_6439d2cfa7da4ab79249d052b9ac4b88",
              "IPY_MODEL_4b93ab0ffc98479d972f83b31a8735ce"
            ],
            "layout": "IPY_MODEL_ea7d776b510349839e1c223eb59ed975"
          }
        },
        "6439d2cfa7da4ab79249d052b9ac4b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9b17419d8084c57ac9ae8bd6d8938be",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3619ead1da764c19b5bfbe1af6f33d5d",
            "value": 898822
          }
        },
        "67745a44d08c4bd0aa6532e8c2cad67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b049209dc4a14025955e9c55326cc1a4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c64bdb95c8f409b9da2ead96e3da851",
            "value": 1
          }
        },
        "6c64bdb95c8f409b9da2ead96e3da851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d5c770b70b04186a71307368ed958df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f40ceb9706b48c2945386766f72050b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d29e33fde11941f4ade74102a50b458e",
              "IPY_MODEL_6fbcac8ffcb748dab17750d69e1130b4",
              "IPY_MODEL_1708b949bc8244bdb1fc0708985f9b68"
            ],
            "layout": "IPY_MODEL_627706204c714b0f9adb90e4863a675a"
          }
        },
        "6fbcac8ffcb748dab17750d69e1130b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5b39e8422e141f58c0e6e6a3cd5c78f",
            "max": 6077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9fc1c26ec0440ebb735de71d674e282",
            "value": 6077
          }
        },
        "72a0b15624784ae1a4dc508c26be6335": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eee4cbb64594125ba097ef895149332",
            "max": 498617024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_997b7f58dd54471986b2bef7a5c29e08",
            "value": 498617024
          }
        },
        "73d21c37af80427494ef33a3b12c0a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79c95fd7d8e14ff78e61cf59fa00437d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61c94e61b7154d7581a85eb42be9eb29",
            "placeholder": "​",
            "style": "IPY_MODEL_2034d891cdbd4a0aa94f16728d6daa8c",
            "value": "100%"
          }
        },
        "80b7dfb0d03f4ce18b13d21c8d13c1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e651bc7d814967b1db88ec26b2493d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b70dbbc3544a3a96805073aee3b4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33d7611f6d42497a8b3d693f725c7630",
              "IPY_MODEL_72a0b15624784ae1a4dc508c26be6335",
              "IPY_MODEL_53586e54851f4464a5daef12409605aa"
            ],
            "layout": "IPY_MODEL_3b8f2da6455641b3bffb2a1a2eb7993a"
          }
        },
        "87a406a991df4e228d360a1e8121a30e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0762c3136040b59817774257e30d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ae8a790b014246b39d7038c731ecb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43be9df75b9942dd9b94b2c7c5a0ed65",
            "placeholder": "​",
            "style": "IPY_MODEL_991ff16f353447bb95a49742e0466259",
            "value": "vocab.json: 100%"
          }
        },
        "91c736bd8d6e47efaab52f859e46d6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9380fd47c089424484129b412b6f8aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991ff16f353447bb95a49742e0466259": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "997b7f58dd54471986b2bef7a5c29e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b13f5ca8b9a43e180adfce066b7395b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a47a1c2dc78e48e1bc34926aa9fc6baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_390e574222b041479836a972c293c369",
              "IPY_MODEL_d0b6533160e44952b80736c724053f17",
              "IPY_MODEL_0231d2ea90904a9db9a015a9fb0148cd"
            ],
            "layout": "IPY_MODEL_4eeae1ea45d444409be7632eeb763bb9"
          }
        },
        "a61fc9b67f86491398580b5ad439903b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b553469f224ce288024bc315e76da1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8725c3887d34a9586dbff91898fcb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77597522a7e4a1288874c0018cd6c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_bc1be7dbf47c477f9efe8b9c03158b21",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a9b17419d8084c57ac9ae8bd6d8938be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac55e8fdb7314f278a76d0f3081e871d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad114a55cdae4d9b837f5b0f65a7939b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afaabd1885c6416f95dbba4ec96540bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b049209dc4a14025955e9c55326cc1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a5991393fe4e5ea3ac4419250b7d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b088f268c84f6f9625698d5bf87878",
            "max": 816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daf3a0400bad4f4689ff56055ac7dfbb",
            "value": 816
          }
        },
        "b2a94115cff14ea08c3f874da035975b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d7f07d062646cca3ca3da576de50da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6e38e5c622b420db4dfda38665fd8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79c95fd7d8e14ff78e61cf59fa00437d",
              "IPY_MODEL_67745a44d08c4bd0aa6532e8c2cad67c",
              "IPY_MODEL_16f4cfef764b444bb3c9c46531d27aac"
            ],
            "layout": "IPY_MODEL_41963b7d46224ea4abbc27fc864373f9"
          }
        },
        "b8a561e28ff04779a77e890b08d82b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc1be7dbf47c477f9efe8b9c03158b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0fe423fdf914757acc260e8c277f785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5515f572725642db831af8d9eeb71b88",
              "IPY_MODEL_37486c608beb4f20986783656895adaa",
              "IPY_MODEL_120994f8f5144079b5dad8eb594ff31c"
            ],
            "layout": "IPY_MODEL_80b7dfb0d03f4ce18b13d21c8d13c1d1"
          }
        },
        "c9fc1c26ec0440ebb735de71d674e282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc1a663763eb4082a791a0431eb44794": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3cf60a077d435ca2d796ef581da563": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf7eebe9cc4e4625b03e2758d25d5381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fafa8b55ad4941ccbdbe733e88e9794a",
              "IPY_MODEL_6258d9f4e0264b578e43e7f1f57577b8",
              "IPY_MODEL_3f61ec011a844e1b859e5d0e4d5e481e"
            ],
            "layout": "IPY_MODEL_cc1a663763eb4082a791a0431eb44794"
          }
        },
        "d0b6533160e44952b80736c724053f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e124fbd133f040c581be2a6ad9f19d4c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d5c770b70b04186a71307368ed958df",
            "value": 1
          }
        },
        "d29e33fde11941f4ade74102a50b458e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09bf686009ce464091955d269b42eec2",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a561e28ff04779a77e890b08d82b4e",
            "value": "Downloading builder script: 100%"
          }
        },
        "d4de634483a94e70a5080bf454938542": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5b39e8422e141f58c0e6e6a3cd5c78f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d734e8b9f79943928609b58d85dd0bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf3a0400bad4f4689ff56055ac7dfbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e124fbd133f040c581be2a6ad9f19d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3617d3da5f3429c86ce71dba891a651": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b088f268c84f6f9625698d5bf87878": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e4c250030b4c93b53594244723d7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea7d776b510349839e1c223eb59ed975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4562473fbb4b1f969978aaf342f395": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3cf60a077d435ca2d796ef581da563",
            "placeholder": "​",
            "style": "IPY_MODEL_36075862c2c342389ea1c899d410037e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f184c39eae274e44a230a53916cabdce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2affab38fba4c41ac1e98823cbe6825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6e599bb3b634069b2b0d2a6b2081746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7438ed1cb3d467cb0410b926b9badae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77597522a7e4a1288874c0018cd6c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d972513c3e4d719632d13b8c8feeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fafa8b55ad4941ccbdbe733e88e9794a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e7242dab3841379e6069b00846b8f7",
            "placeholder": "​",
            "style": "IPY_MODEL_8b0762c3136040b59817774257e30d2f",
            "value": "merges.txt: 100%"
          }
        },
        "fe7dbe185fdf435e93254877507d1f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac55e8fdb7314f278a76d0f3081e871d",
            "placeholder": "​",
            "style": "IPY_MODEL_00ac0b6469ec4d909cee465aa90b199b",
            "value": " 239/239 [00:00&lt;00:00, 15.5kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}